---
layout: default
---


# Nonlinear Algebra Seminar
December 12, 2 - 5 pm (tentative)\\
Evans 740, UC Berkeley


## Speakers and Abstracts



<span class="header-color">Speaker:</span>
Kristen Dawson (San Francisco State Univeristy)\\
<span class="header-color">Title:</span>
\\
<span class="header-color">Abstract:</span>




<span class="header-color">Speaker:</span>
[Svala Sverissd√≥ttir](https://math.berkeley.edu/~svala/){:target="_blank"} (UC Berkeley)\\
<span class="header-color">Title:</span>
\\
<span class="header-color">Abstract:</span>


<span class="header-color">Speaker:</span>
[Ruriko Yoshida](http://www.polytopes.net){:target="_blank"} (Naval Postgradaute School)\\
<span class="header-color">Title:</span>
Tropical Fermat-Weber Polytropes\\
<span class="header-color">Abstract:</span>
In this talk we discuss the geometry of tropical Fermat-Weber points in terms of the symmetric tropical metric over the tropical projective torus.  It is well-known that a tropical Fermat-Weber point of a given sample is not unique and we show that the set of all possible Fermat-Weber points forms a polytrope. To prove this, we show that the tropical Fermat-Weber polytrope is a bounded cell of a tropical hyperplane arrangement given by both max- and min-tropical hyperplanes with apices given by the sample. We also define tropical Fermat-Weber gradients and provide a gradient descent algorithm that converges to the Fermat-Weber polytrope.  This is joint work with J. Sabol, D. Barnhill and K. Miura. 


<span class="header-color">Speaker:</span>
[Maksym Zubkov](https://maksymzubkov.info){:target="_blank"} (University of British Columbia)\\
<span class="header-color">Title:</span>
The Geometry of Rational Neural Networks \\
<span class="header-color">Abstract:</span>
Rational neural networks are feedforward neural networks with a rational activation function. These networks found their applications in approximating the solutions of PDE, as they are able to learn the poles of meromorphic functions. In this talk, we are going to consider the simplest rational activation function, sigma = 1 / x, and study the geometry of family such architectures. We will show that the closure of all possible shallow (one hidden layer) networks is an algebraic variety, which called a neurovariety.

## Schedule
TBD